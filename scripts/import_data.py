#!/usr/bin/env python3
"""åšåŠ´çœCSVã‚’DBã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""

import csv
import sys
import json
from pathlib import Path
from datetime import date

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))

from api.database import engine, SessionLocal, Base
from api.models import (
    Prefecture, City, SpecialtyMaster,
    Facility, Specialty, HospitalBed, BusinessHour
)

RAW_DIR = Path(__file__).parent.parent / "data" / "raw"

# éƒ½é“åºœçœŒãƒã‚¹ã‚¿
PREFECTURES = {
    "01": "åŒ—æµ·é“", "02": "é’æ£®çœŒ", "03": "å²©æ‰‹çœŒ", "04": "å®®åŸçœŒ", "05": "ç§‹ç”°çœŒ",
    "06": "å±±å½¢çœŒ", "07": "ç¦å³¶çœŒ", "08": "èŒ¨åŸçœŒ", "09": "æ ƒæœ¨çœŒ", "10": "ç¾¤é¦¬çœŒ",
    "11": "åŸ¼ç‰çœŒ", "12": "åƒè‘‰çœŒ", "13": "æ±äº¬éƒ½", "14": "ç¥å¥ˆå·çœŒ", "15": "æ–°æ½ŸçœŒ",
    "16": "å¯Œå±±çœŒ", "17": "çŸ³å·çœŒ", "18": "ç¦äº•çœŒ", "19": "å±±æ¢¨çœŒ", "20": "é•·é‡çœŒ",
    "21": "å²é˜œçœŒ", "22": "é™å²¡çœŒ", "23": "æ„›çŸ¥çœŒ", "24": "ä¸‰é‡çœŒ", "25": "æ»‹è³€çœŒ",
    "26": "äº¬éƒ½åºœ", "27": "å¤§é˜ªåºœ", "28": "å…µåº«çœŒ", "29": "å¥ˆè‰¯çœŒ", "30": "å’Œæ­Œå±±çœŒ",
    "31": "é³¥å–çœŒ", "32": "å³¶æ ¹çœŒ", "33": "å²¡å±±çœŒ", "34": "åºƒå³¶çœŒ", "35": "å±±å£çœŒ",
    "36": "å¾³å³¶çœŒ", "37": "é¦™å·çœŒ", "38": "æ„›åª›çœŒ", "39": "é«˜çŸ¥çœŒ", "40": "ç¦å²¡çœŒ",
    "41": "ä½è³€çœŒ", "42": "é•·å´çœŒ", "43": "ç†Šæœ¬çœŒ", "44": "å¤§åˆ†çœŒ", "45": "å®®å´çœŒ",
    "46": "é¹¿å…å³¶çœŒ", "47": "æ²–ç¸„çœŒ",
}

# è¨ºç™‚ç§‘ã‚«ãƒ†ã‚´ãƒª
SPECIALTY_CATEGORIES = {
    "01": "å†…ç§‘ç³»", "02": "å¤–ç§‘ç³»", "03": "å°å…ç§‘ç³»", "04": "ç”£å©¦äººç§‘ç³»",
    "05": "çœ¼ç§‘ãƒ»è€³é¼»ç§‘ç³»", "06": "çš®è†šãƒ»æ³Œå°¿å™¨ç§‘ç³»", "07": "ç²¾ç¥ç§‘ç³»",
    "08": "æ­¯ç§‘ç³»", "09": "ãã®ä»–",
}

DAYS = ["mon", "tue", "wed", "thu", "fri", "sat", "sun", "hol"]
DATA_DATE = date(2025, 12, 1)


def safe_int(v):
    """ç©ºæ–‡å­—ã‚„Noneã‚’å®‰å…¨ã«intã«å¤‰æ›"""
    if not v or v.strip() == "":
        return None
    try:
        return int(v)
    except ValueError:
        return None


def safe_float(v):
    if not v or v.strip() == "":
        return None
    try:
        f = float(v)
        return f if f != 0.0 else None  # 0.0ã¯æœªç™»éŒ²æ‰±ã„
    except ValueError:
        return None


def parse_closed_weekly(row, start_col):
    """æ›œæ—¥åˆ¥ä¼‘è¨ºãƒ•ãƒ©ã‚°ã‚’JSONåŒ–"""
    days_jp = ["mon", "tue", "wed", "thu", "fri", "sat", "sun"]
    result = {}
    for i, day in enumerate(days_jp):
        val = row[start_col + i].strip() if start_col + i < len(row) else ""
        result[day] = val == "1"
    return result


def parse_closed_weeks(row, start_col):
    """å®šæœŸé€±ä¼‘è¨ºãƒ•ãƒ©ã‚°ã‚’JSONåŒ–ï¼ˆ5é€±Ã—7æ›œæ—¥=35ã‚«ãƒ©ãƒ ï¼‰"""
    days_jp = ["mon", "tue", "wed", "thu", "fri", "sat", "sun"]
    result = {}
    for week in range(5):
        week_data = {}
        for i, day in enumerate(days_jp):
            col = start_col + week * 7 + i
            val = row[col].strip() if col < len(row) else ""
            week_data[day] = val == "1"
        if any(week_data.values()):
            result[f"week{week+1}"] = week_data
    return result if result else None


def parse_schedule(row, start_col):
    """æ›œæ—¥åˆ¥ã®é–‹å§‹/çµ‚äº†æ™‚é–“ãƒšã‚¢ã‚’JSONåŒ–"""
    schedule = {}
    for i, day in enumerate(DAYS):
        s_col = start_col + i * 2
        e_col = s_col + 1
        start = row[s_col].strip() if s_col < len(row) else ""
        end = row[e_col].strip() if e_col < len(row) else ""
        if start and end:
            schedule[day] = {"start": start, "end": end}
        else:
            schedule[day] = None
    return schedule


def import_prefectures(session):
    """éƒ½é“åºœçœŒãƒã‚¹ã‚¿"""
    print("ğŸ“ éƒ½é“åºœçœŒãƒã‚¹ã‚¿...")
    for code, name in PREFECTURES.items():
        session.merge(Prefecture(code=code, name=name))
    session.commit()
    print(f"   {len(PREFECTURES)}ä»¶")


def import_cities(session):
    """å¸‚åŒºç”ºæ‘ãƒã‚¹ã‚¿ï¼ˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æŠ½å‡ºï¼‰"""
    print("ğŸ˜ï¸  å¸‚åŒºç”ºæ‘ãƒã‚¹ã‚¿...")
    cities = {}

    for fname in RAW_DIR.glob("*.csv"):
        with open(fname, encoding="utf-8-sig") as f:
            reader = csv.reader(f)
            header = next(reader)

            # ã‚«ãƒ©ãƒ ä½ç½®ã‚’ç‰¹å®š
            pref_idx = None
            city_idx = None
            addr_idx = None
            for i, h in enumerate(header):
                if h == "éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰":
                    pref_idx = i
                elif h == "å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰":
                    city_idx = i
                elif h == "æ‰€åœ¨åœ°":
                    addr_idx = i

            if pref_idx is None or city_idx is None:
                continue

            for row in reader:
                pcode = row[pref_idx].strip()
                ccode = row[city_idx].strip()
                if pcode and ccode and (pcode, ccode) not in cities:
                    # ä½æ‰€ã‹ã‚‰å¸‚åŒºç”ºæ‘åã‚’æ¨å®šï¼ˆéƒ½é“åºœçœŒåã‚’é™¤ã„ãŸå…ˆé ­éƒ¨åˆ†ï¼‰
                    addr = row[addr_idx].strip() if addr_idx and addr_idx < len(row) else ""
                    # éƒ½é“åºœçœŒåã‚’é™¤å»ã—ã¦å¸‚åŒºç”ºæ‘åã‚’æŠ½å‡º
                    pref_name = PREFECTURES.get(pcode, "")
                    city_name = addr.replace(pref_name, "").split("åŒº")[0] + "åŒº" if "åŒº" in addr.replace(pref_name, "") else ""
                    if not city_name:
                        city_name = ccode  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    cities[(pcode, ccode)] = city_name

    for (pcode, ccode), name in cities.items():
        session.merge(City(prefecture_code=pcode, code=ccode, name=name))
    session.commit()
    print(f"   {len(cities)}ä»¶")


def import_facility_file(session, filename, facility_type, bed_start_col=None, bed_cols=None):
    """æ–½è¨­CSVã‚’å–ã‚Šè¾¼ã¿"""
    filepath = RAW_DIR / filename
    if not filepath.exists():
        print(f"   âš ï¸ {filename} not found, skipping")
        return 0

    count = 0
    with open(filepath, encoding="utf-8-sig") as f:
        reader = csv.reader(f)
        header = next(reader)

        for row in reader:
            if len(row) < 13:
                continue

            # è–¬å±€ã¯ã‚«ãƒ©ãƒ æ§‹æˆãŒç•°ãªã‚‹
            if facility_type == 5:
                fac = Facility(
                    id=row[0].strip(),
                    facility_type=facility_type,
                    name=row[1].strip(),
                    name_kana=row[2].strip() or None,
                    name_short=None,
                    name_en=row[3].strip() or None,
                    prefecture_code=row[5].strip(),
                    city_code=row[6].strip(),
                    address=row[7].strip() or None,
                    latitude=safe_float(row[8]),
                    longitude=safe_float(row[9]),
                    website_url=row[10].strip() or None,
                    closed_holiday=row[62].strip() == "1" if len(row) > 62 else None,
                    closed_other=row[63].strip() or None if len(row) > 63 else None,
                    closed_weekly=parse_closed_weekly(row, 19),  # å®šæœŸé–‰åº—æ¯é€±
                    closed_weeks=None,  # è–¬å±€ã¯å®šæœŸé€±ãªã—ï¼ˆåˆ¥å½¢å¼ï¼‰
                    data_date=DATA_DATE,
                )
            else:
                fac = Facility(
                    id=row[0].strip(),
                    facility_type=facility_type,
                    name=row[1].strip(),
                    name_kana=row[2].strip() or None,
                    name_short=row[3].strip() or None,
                    name_en=row[5].strip() or None,
                    prefecture_code=row[7].strip(),
                    city_code=row[8].strip(),
                    address=row[9].strip() or None,
                    latitude=safe_float(row[10]),
                    longitude=safe_float(row[11]),
                    website_url=row[12].strip() or None,
                    closed_holiday=row[55].strip() == "1" if len(row) > 55 else None,
                    closed_other=row[56].strip() or None if len(row) > 56 else None,
                    closed_weekly=parse_closed_weekly(row, 13),
                    closed_weeks=parse_closed_weeks(row, 20),
                    data_date=DATA_DATE,
                )

            session.merge(fac)

            # ç—…åºŠæƒ…å ±ï¼ˆç—…é™¢ãƒ»è¨ºç™‚æ‰€ã®ã¿ï¼‰
            if bed_start_col and bed_cols:
                bed_data = {}
                for i, col_name in enumerate(bed_cols):
                    idx = bed_start_col + i
                    bed_data[col_name] = safe_int(row[idx]) if idx < len(row) else None
                if any(v is not None for v in bed_data.values()):
                    session.merge(HospitalBed(facility_id=row[0].strip(), **bed_data))

            count += 1
            if count % 2000 == 0:
                session.commit()
                print(f"   {count:,}...")

    session.commit()
    return count


def import_speciality_file(session, filename):
    """è¨ºç™‚ç§‘CSVã‚’å–ã‚Šè¾¼ã¿ï¼ˆãƒãƒ«ã‚¯ã‚¤ãƒ³ã‚µãƒ¼ãƒˆï¼‰"""
    filepath = RAW_DIR / filename
    if not filepath.exists():
        print(f"   âš ï¸ {filename} not found, skipping")
        return 0

    count = 0
    batch = []
    BATCH_SIZE = 5000

    with open(filepath, encoding="utf-8-sig") as f:
        reader = csv.reader(f)
        next(reader)  # header

        for row in reader:
            if len(row) < 36:
                continue

            schedule = parse_schedule(row, 4)
            reception = parse_schedule(row, 20)

            batch.append({
                "facility_id": row[0].strip(),
                "specialty_code": row[1].strip() or None,
                "specialty_name": row[2].strip(),
                "time_slot": row[3].strip() or None,
                "schedule": json.dumps(schedule, ensure_ascii=False),
                "reception": json.dumps(reception, ensure_ascii=False),
            })
            count += 1

            if len(batch) >= BATCH_SIZE:
                session.execute(Specialty.__table__.insert(), batch)
                session.commit()
                batch = []
                print(f"   {count:,}...")

    if batch:
        session.execute(Specialty.__table__.insert(), batch)
        session.commit()

    return count


def import_specialty_master(session):
    """è¨ºç™‚ç§‘ãƒã‚¹ã‚¿ï¼ˆæ­£è¦ã‚³ãƒ¼ãƒ‰ã®ã¿ï¼‰"""
    print("ğŸ·ï¸  è¨ºç™‚ç§‘ãƒã‚¹ã‚¿...")
    seen = set()

    for fname in ["01-2_hospital_speciality_hours_20251201.csv",
                   "02-2_clinic_speciality_hours_20251201.csv",
                   "03-2_dental_speciality_hours_20251201.csv"]:
        filepath = RAW_DIR / fname
        if not filepath.exists():
            continue
        with open(filepath, encoding="utf-8-sig") as f:
            reader = csv.reader(f)
            next(reader)
            for row in reader:
                code = row[1].strip()
                name = row[2].strip()
                # XX991ã¯ã€Œãã®ä»–ã€è‡ªç”±è¨˜è¿°ãªã®ã§ãƒã‚¹ã‚¿ã«å…¥ã‚Œãªã„
                if code and not code.endswith("991") and code not in seen:
                    cat_key = code[:2]
                    category = SPECIALTY_CATEGORIES.get(cat_key, "ãã®ä»–")
                    session.merge(SpecialtyMaster(code=code, name=name, category=category))
                    seen.add(code)

    session.commit()
    print(f"   {len(seen)}ä»¶")


def import_business_hours_pharmacy(session):
    """è–¬å±€ã®å–¶æ¥­æ™‚é–“å¸¯ã‚’å–ã‚Šè¾¼ã¿"""
    filepath = RAW_DIR / "05_pharmacy_20251201.csv"
    if not filepath.exists():
        return 0

    print("ğŸ• è–¬å±€å–¶æ¥­æ™‚é–“...")
    count = 0

    with open(filepath, encoding="utf-8-sig") as f:
        reader = csv.reader(f)
        next(reader)

        for row in reader:
            fac_id = row[0].strip()
            # 4ã‚¹ãƒ­ãƒƒãƒˆ Ã— é–‹åº—æ™‚é–“å¸¯ (col 64-127)
            for slot in range(4):
                base = 64 + slot * 16
                schedule = parse_schedule(row, base)
                if any(v is not None for v in schedule.values()):
                    session.add(BusinessHour(
                        facility_id=fac_id,
                        slot_number=slot + 1,
                        hour_type="business",
                        schedule=schedule,
                    ))
                    count += 1

            if count % 10000 == 0 and count > 0:
                session.flush()

    session.commit()
    return count


def import_business_hours_maternity(session):
    """åŠ©ç”£æ‰€ã®å°±æ¥­æ™‚é–“ãƒ»å—ä»˜æ™‚é–“ã‚’å–ã‚Šè¾¼ã¿"""
    filepath = RAW_DIR / "04_maternity_home_20251201.csv"
    if not filepath.exists():
        return 0

    print("ğŸ• åŠ©ç”£æ‰€å–¶æ¥­æ™‚é–“...")
    count = 0

    with open(filepath, encoding="utf-8-sig") as f:
        reader = csv.reader(f)
        next(reader)

        for row in reader:
            fac_id = row[0].strip()
            # å°±æ¥­æ™‚é–“å¸¯ 3ã‚¹ãƒ­ãƒƒãƒˆ (col 57-104)
            for slot in range(3):
                base = 57 + slot * 16
                schedule = parse_schedule(row, base)
                if any(v is not None for v in schedule.values()):
                    session.add(BusinessHour(
                        facility_id=fac_id,
                        slot_number=slot + 1,
                        hour_type="business",
                        schedule=schedule,
                    ))
                    count += 1

            # å¤–æ¥å—ä»˜æ™‚é–“å¸¯ 3ã‚¹ãƒ­ãƒƒãƒˆ (col 105-152)
            for slot in range(3):
                base = 105 + slot * 16
                schedule = parse_schedule(row, base)
                if any(v is not None for v in schedule.values()):
                    session.add(BusinessHour(
                        facility_id=fac_id,
                        slot_number=slot + 1,
                        hour_type="reception",
                        schedule=schedule,
                    ))
                    count += 1

    session.commit()
    return count


def main():
    print("ğŸ—„ï¸  ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ...")
    Base.metadata.create_all(engine)

    session = SessionLocal()
    try:
        # ãƒã‚¹ã‚¿
        import_prefectures(session)
        import_cities(session)
        import_specialty_master(session)

        # æ–½è¨­ï¼ˆç—…é™¢ï¼‰
        hospital_bed_cols = ["general", "recuperation", "recuperation_medical",
                             "recuperation_nursing", "psychiatric", "tuberculosis",
                             "infectious", "total"]
        print("ğŸ¥ ç—…é™¢...")
        n = import_facility_file(session, "01-1_hospital_facility_info_20251201.csv",
                                 facility_type=1, bed_start_col=57, bed_cols=hospital_bed_cols)
        print(f"   âœ… {n:,}ä»¶")

        # æ–½è¨­ï¼ˆè¨ºç™‚æ‰€ï¼‰
        clinic_bed_cols = ["general", "recuperation", "recuperation_medical",
                           "recuperation_nursing", "total"]
        print("ğŸ¥ è¨ºç™‚æ‰€...")
        n = import_facility_file(session, "02-1_clinic_facility_info_20251201.csv",
                                 facility_type=2, bed_start_col=57, bed_cols=clinic_bed_cols)
        print(f"   âœ… {n:,}ä»¶")

        # æ–½è¨­ï¼ˆæ­¯ç§‘ï¼‰
        print("ğŸ¦· æ­¯ç§‘è¨ºç™‚æ‰€...")
        n = import_facility_file(session, "03-1_dental_facility_info_20251201.csv",
                                 facility_type=3)
        print(f"   âœ… {n:,}ä»¶")

        # æ–½è¨­ï¼ˆåŠ©ç”£æ‰€ï¼‰
        print("ğŸ‘¶ åŠ©ç”£æ‰€...")
        n = import_facility_file(session, "04_maternity_home_20251201.csv",
                                 facility_type=4)
        print(f"   âœ… {n:,}ä»¶")

        # æ–½è¨­ï¼ˆè–¬å±€ï¼‰
        print("ğŸ’Š è–¬å±€...")
        n = import_facility_file(session, "05_pharmacy_20251201.csv",
                                 facility_type=5)
        print(f"   âœ… {n:,}ä»¶")

        # è¨ºç™‚ç§‘
        print("ğŸ“‹ ç—…é™¢ è¨ºç™‚ç§‘...")
        n = import_speciality_file(session, "01-2_hospital_speciality_hours_20251201.csv")
        print(f"   âœ… {n:,}ä»¶")

        print("ğŸ“‹ è¨ºç™‚æ‰€ è¨ºç™‚ç§‘...")
        n = import_speciality_file(session, "02-2_clinic_speciality_hours_20251201.csv")
        print(f"   âœ… {n:,}ä»¶")

        print("ğŸ“‹ æ­¯ç§‘ è¨ºç™‚ç§‘...")
        n = import_speciality_file(session, "03-2_dental_speciality_hours_20251201.csv")
        print(f"   âœ… {n:,}ä»¶")

        # å–¶æ¥­æ™‚é–“
        n = import_business_hours_pharmacy(session)
        print(f"   âœ… è–¬å±€å–¶æ¥­æ™‚é–“ {n:,}ä»¶")

        n = import_business_hours_maternity(session)
        print(f"   âœ… åŠ©ç”£æ‰€å–¶æ¥­æ™‚é–“ {n:,}ä»¶")

        print("\nğŸ‰ ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†!")

    finally:
        session.close()


if __name__ == "__main__":
    main()
